---
title: "IoTの目線からApache Kafkaについて勉強した"
emoji: "🐙"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: true
---

# 背景
Google PubSub, Redis PubSub, AWS SNSなどある中、Apache Kafkaも広く使われているが実際のところ何ができるのかわからない。
IoT系の会社にいるので今後数千、数万のIoTツールとのやり取りをそれぞれのデバイスに適切に送るにはどうすればいいのか、その手段を探る上でApache Kafkaについても理解したい。

ざっくり要件は
- WebSocketで繋がっているデバイスに対してメッセージを送りたい
- メッセージは特定のデバイス1つに対して送る
- 数千、数万のIoTデバイスとのやりとりにスケール可能
- どうやって状態を観測するのか


# Apache Kafkaについて知るためにこの記事を読んだ
https://www.redhat.com/ja/blog/apache-kafka-10-essential-terms-and-concepts-explained


- ブローカー
- 複数のブローカー -> クラスター
- オフセット、これが順番を決めるIDになるっぽい
- Apache ZooKeeperで管理することができるが、Apache Kafka 3.0.0から段階的に廃止
    - どうすればいいのだ？


この記事ではなんとなく登場人物と用語を把握できた。それ以上はちょっとわからない。

# 次にGoogle PubSubを実務で使っているので、その比較の記事読んでみた
https://developers.cyberagent.co.jp/blog/archives/1672/

IoTデバイスごとにTopicを作る場合、どうなる？

- Apache Kafka: 上限なし
- Google PubSub: GCPプロジェクトで10,000が最大

Apache Kafkaの方が柔軟性は高そう。

IoTデバイス<->WebSocketサーバ<->Kafka Cluster
の場合、IoTデバイスが増えるたびWebSocketサーバからKafka Clusterに対して接続を増やす必要あり

Google PubSubと違って自分たちで自前で構築の必要があるから、障害時に対応できるようにする必要ありだな、その場合どうする？ -> AWS IoT Coreなど他社クラウドのマネージドも検討した方が良さそう

# 少し話が変わって、GCPにIoT周りのアーキテクチャに関して記事読んでみる
https://cloud.google.com/architecture/connected-devices?hl=ja

ざっくりな構成しか書いてない、IoTデバイスに対して具体的にどのようなフローでメッセージを送るように作ればいいのかいまいちわからない。


# まとめ
大規模なチームならApache Kafkaを検討してもいいかもしれない。

- Kafka Clusterを自前で作る
- 運用、管理する
- そもそも知見がない場合はかなり慎重に検討必要
    - サービスに求められる可用性とそれを担保できるだけの技術力、体制があることが鍵

リソースがあるのかが課題だと思う。


デバイスの数が数千から数万くらいならAWS IoT Coreなどのマネージドなサービスを使う方がよさそう。